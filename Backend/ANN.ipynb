{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv=pd.read_csv(r'C:\\Users\\HIRANMAYI\\Final year project\\dataset.csv',delimiter=',')\n",
    "data_npz=np.array(data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= (25345, 394)\n",
      "y= (25345, 1)\n"
     ]
    }
   ],
   "source": [
    "df=data_csv\n",
    "df_x=df.iloc[:,0:394]\n",
    "y=df.iloc[:,394].values.reshape(len(df),1)\n",
    "print(\"x=\",df_x.shape)\n",
    "print(\"y=\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7604, 394)\n",
      "(7604, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x,y,test_size=0.3, random_state=0)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#s=StandardScaler()\n",
    "#s.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_scaled=s.transform(x_train)\n",
    "#x_test_scaled=s.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HIRANMAYI\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128,input_dim=394,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               50560     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 58,881\n",
      "Trainable params: 58,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#keras.optimizers.Adam(lr=0.0003)\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HIRANMAYI\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 12418 samples, validate on 5323 samples\n",
      "Epoch 1/100\n",
      "12418/12418 [==============================] - 1s 80us/step - loss: 5342.0989 - mae: 30.4978 - val_loss: 265.6155 - val_mae: 12.8449\n",
      "Epoch 2/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 221.0566 - mae: 11.6949 - val_loss: 142.2394 - val_mae: 9.4146\n",
      "Epoch 3/100\n",
      "12418/12418 [==============================] - 1s 62us/step - loss: 129.1223 - mae: 8.9712 - val_loss: 112.0868 - val_mae: 8.4689\n",
      "Epoch 4/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 97.5770 - mae: 7.7434 - val_loss: 76.2727 - val_mae: 6.8408\n",
      "Epoch 5/100\n",
      "12418/12418 [==============================] - 1s 65us/step - loss: 97.9123 - mae: 7.8163 - val_loss: 66.8865 - val_mae: 6.3475\n",
      "Epoch 6/100\n",
      "12418/12418 [==============================] - 1s 64us/step - loss: 85.7339 - mae: 7.3502 - val_loss: 110.2609 - val_mae: 8.7244\n",
      "Epoch 7/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 79.7323 - mae: 7.0899 - val_loss: 79.6253 - val_mae: 7.2351\n",
      "Epoch 8/100\n",
      "12418/12418 [==============================] - 1s 64us/step - loss: 69.8484 - mae: 6.5994 - val_loss: 63.6344 - val_mae: 6.2147\n",
      "Epoch 9/100\n",
      "12418/12418 [==============================] - 1s 63us/step - loss: 75.5704 - mae: 6.8229 - val_loss: 56.3242 - val_mae: 5.9823\n",
      "Epoch 10/100\n",
      "12418/12418 [==============================] - 1s 65us/step - loss: 69.0962 - mae: 6.5827 - val_loss: 45.2757 - val_mae: 5.2084\n",
      "Epoch 11/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 69.5060 - mae: 6.6332 - val_loss: 114.5364 - val_mae: 9.2225\n",
      "Epoch 12/100\n",
      "12418/12418 [==============================] - 1s 65us/step - loss: 65.7882 - mae: 6.4193 - val_loss: 41.2711 - val_mae: 4.9684\n",
      "Epoch 13/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 61.6307 - mae: 6.1999 - val_loss: 122.7124 - val_mae: 9.2651\n",
      "Epoch 14/100\n",
      "12418/12418 [==============================] - 1s 64us/step - loss: 56.9356 - mae: 5.9469 - val_loss: 53.7826 - val_mae: 5.8664\n",
      "Epoch 15/100\n",
      "12418/12418 [==============================] - 1s 61us/step - loss: 57.0667 - mae: 5.9479 - val_loss: 74.0206 - val_mae: 7.1133\n",
      "Epoch 16/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 56.4793 - mae: 5.8970 - val_loss: 54.5549 - val_mae: 5.8357\n",
      "Epoch 17/100\n",
      "12418/12418 [==============================] - 1s 65us/step - loss: 49.0283 - mae: 5.4541 - val_loss: 174.6233 - val_mae: 11.9613\n",
      "Epoch 18/100\n",
      "12418/12418 [==============================] - 1s 63us/step - loss: 53.1584 - mae: 5.7257 - val_loss: 82.9732 - val_mae: 7.6148\n",
      "Epoch 19/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 48.7044 - mae: 5.4466 - val_loss: 112.6976 - val_mae: 9.2210\n",
      "Epoch 20/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 50.2547 - mae: 5.5511 - val_loss: 87.8236 - val_mae: 7.9102\n",
      "Epoch 21/100\n",
      "12418/12418 [==============================] - 1s 118us/step - loss: 48.1750 - mae: 5.4214 - val_loss: 42.4948 - val_mae: 5.0198\n",
      "Epoch 22/100\n",
      "12418/12418 [==============================] - 1s 109us/step - loss: 46.9359 - mae: 5.3373 - val_loss: 44.6473 - val_mae: 5.2235\n",
      "Epoch 23/100\n",
      "12418/12418 [==============================] - 1s 88us/step - loss: 49.5764 - mae: 5.5138 - val_loss: 63.2943 - val_mae: 6.2795\n",
      "Epoch 24/100\n",
      "12418/12418 [==============================] - 1s 92us/step - loss: 43.4911 - mae: 5.1143 - val_loss: 34.8694 - val_mae: 4.5602\n",
      "Epoch 25/100\n",
      "12418/12418 [==============================] - 1s 101us/step - loss: 45.7744 - mae: 5.2900 - val_loss: 41.3542 - val_mae: 5.0314\n",
      "Epoch 26/100\n",
      "12418/12418 [==============================] - 1s 94us/step - loss: 43.7344 - mae: 5.1430 - val_loss: 43.8914 - val_mae: 5.2716\n",
      "Epoch 27/100\n",
      "12418/12418 [==============================] - 1s 101us/step - loss: 43.3660 - mae: 5.1458 - val_loss: 104.4320 - val_mae: 8.5769\n",
      "Epoch 28/100\n",
      "12418/12418 [==============================] - 1s 98us/step - loss: 50.0374 - mae: 5.5274 - val_loss: 34.3656 - val_mae: 4.5147\n",
      "Epoch 29/100\n",
      "12418/12418 [==============================] - 1s 102us/step - loss: 43.1528 - mae: 5.1171 - val_loss: 104.6273 - val_mae: 8.6753\n",
      "Epoch 30/100\n",
      "12418/12418 [==============================] - 1s 96us/step - loss: 41.6192 - mae: 5.0004 - val_loss: 46.2808 - val_mae: 5.4426\n",
      "Epoch 31/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 39.7235 - mae: 4.9102 - val_loss: 43.6235 - val_mae: 5.1986\n",
      "Epoch 32/100\n",
      "12418/12418 [==============================] - 1s 74us/step - loss: 41.0236 - mae: 4.9735 - val_loss: 51.6864 - val_mae: 5.7802\n",
      "Epoch 33/100\n",
      "12418/12418 [==============================] - 1s 74us/step - loss: 40.4458 - mae: 4.9508 - val_loss: 95.5522 - val_mae: 8.4002\n",
      "Epoch 34/100\n",
      "12418/12418 [==============================] - 1s 75us/step - loss: 38.8100 - mae: 4.8254 - val_loss: 48.7838 - val_mae: 5.5644\n",
      "Epoch 35/100\n",
      "12418/12418 [==============================] - 1s 74us/step - loss: 42.7614 - mae: 5.0718 - val_loss: 48.1670 - val_mae: 5.6216\n",
      "Epoch 36/100\n",
      "12418/12418 [==============================] - 1s 74us/step - loss: 37.4966 - mae: 4.7723 - val_loss: 36.8143 - val_mae: 4.6919\n",
      "Epoch 37/100\n",
      "12418/12418 [==============================] - 1s 77us/step - loss: 36.3892 - mae: 4.6621 - val_loss: 57.3427 - val_mae: 6.1872\n",
      "Epoch 38/100\n",
      "12418/12418 [==============================] - 1s 77us/step - loss: 36.3656 - mae: 4.6846 - val_loss: 42.7260 - val_mae: 5.2103\n",
      "Epoch 39/100\n",
      "12418/12418 [==============================] - 1s 72us/step - loss: 34.9732 - mae: 4.5756 - val_loss: 31.5310 - val_mae: 4.3551\n",
      "Epoch 40/100\n",
      "12418/12418 [==============================] - 1s 79us/step - loss: 36.2477 - mae: 4.6570 - val_loss: 36.2518 - val_mae: 4.6925\n",
      "Epoch 41/100\n",
      "12418/12418 [==============================] - 1s 78us/step - loss: 38.8547 - mae: 4.8501 - val_loss: 84.6819 - val_mae: 7.7416\n",
      "Epoch 42/100\n",
      "12418/12418 [==============================] - 1s 79us/step - loss: 38.1811 - mae: 4.7779 - val_loss: 36.4174 - val_mae: 4.7278\n",
      "Epoch 43/100\n",
      "12418/12418 [==============================] - 1s 78us/step - loss: 35.0990 - mae: 4.5806 - val_loss: 51.8917 - val_mae: 5.8079\n",
      "Epoch 44/100\n",
      "12418/12418 [==============================] - 1s 75us/step - loss: 34.3839 - mae: 4.5119 - val_loss: 39.3563 - val_mae: 4.7996\n",
      "Epoch 45/100\n",
      "12418/12418 [==============================] - 1s 68us/step - loss: 38.0903 - mae: 4.7807 - val_loss: 45.4175 - val_mae: 5.4409\n",
      "Epoch 46/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 36.4727 - mae: 4.6880 - val_loss: 31.2877 - val_mae: 4.2982\n",
      "Epoch 47/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 33.6217 - mae: 4.4697 - val_loss: 57.7594 - val_mae: 6.1973\n",
      "Epoch 48/100\n",
      "12418/12418 [==============================] - 1s 68us/step - loss: 33.9960 - mae: 4.4843 - val_loss: 28.4326 - val_mae: 4.0870\n",
      "Epoch 49/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 31.9696 - mae: 4.3464 - val_loss: 35.1005 - val_mae: 4.6611\n",
      "Epoch 50/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 36.0551 - mae: 4.6335 - val_loss: 37.0090 - val_mae: 4.8368\n",
      "Epoch 51/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 33.1240 - mae: 4.4524 - val_loss: 32.4811 - val_mae: 4.4358\n",
      "Epoch 52/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 32.4747 - mae: 4.4165 - val_loss: 45.1493 - val_mae: 5.4711\n",
      "Epoch 53/100\n",
      "12418/12418 [==============================] - 1s 71us/step - loss: 31.8291 - mae: 4.3481 - val_loss: 41.3658 - val_mae: 5.1098\n",
      "Epoch 54/100\n",
      "12418/12418 [==============================] - 1s 68us/step - loss: 32.8689 - mae: 4.4297 - val_loss: 27.3654 - val_mae: 3.9995\n",
      "Epoch 55/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 32.0493 - mae: 4.3657 - val_loss: 42.0271 - val_mae: 5.2181\n",
      "Epoch 56/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 31.2423 - mae: 4.3251 - val_loss: 66.2721 - val_mae: 6.7625\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12418/12418 [==============================] - 1s 69us/step - loss: 31.7577 - mae: 4.3286 - val_loss: 37.1946 - val_mae: 4.8813\n",
      "Epoch 58/100\n",
      "12418/12418 [==============================] - 1s 65us/step - loss: 32.1162 - mae: 4.3727 - val_loss: 27.6726 - val_mae: 4.0588\n",
      "Epoch 59/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 29.3868 - mae: 4.1856 - val_loss: 56.1067 - val_mae: 6.1745\n",
      "Epoch 60/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 32.9889 - mae: 4.4415 - val_loss: 34.8642 - val_mae: 4.6197\n",
      "Epoch 61/100\n",
      "12418/12418 [==============================] - 1s 65us/step - loss: 30.4211 - mae: 4.2686 - val_loss: 36.0018 - val_mae: 4.7155\n",
      "Epoch 62/100\n",
      "12418/12418 [==============================] - 1s 68us/step - loss: 30.8060 - mae: 4.2875 - val_loss: 35.1194 - val_mae: 4.6799\n",
      "Epoch 63/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 31.2524 - mae: 4.3145 - val_loss: 29.1314 - val_mae: 4.1876\n",
      "Epoch 64/100\n",
      "12418/12418 [==============================] - 1s 64us/step - loss: 30.5517 - mae: 4.2550 - val_loss: 27.4407 - val_mae: 4.0021\n",
      "Epoch 65/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 31.5659 - mae: 4.3256 - val_loss: 30.2872 - val_mae: 4.2490\n",
      "Epoch 66/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 32.3963 - mae: 4.3985 - val_loss: 44.7616 - val_mae: 5.2146\n",
      "Epoch 67/100\n",
      "12418/12418 [==============================] - 1s 68us/step - loss: 29.9757 - mae: 4.1959 - val_loss: 28.9570 - val_mae: 4.1678\n",
      "Epoch 68/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 28.5137 - mae: 4.0919 - val_loss: 64.2593 - val_mae: 6.4403\n",
      "Epoch 69/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 29.4684 - mae: 4.1768 - val_loss: 35.3546 - val_mae: 4.6200\n",
      "Epoch 70/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 29.9045 - mae: 4.2202 - val_loss: 35.2659 - val_mae: 4.6051\n",
      "Epoch 71/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 27.9921 - mae: 4.0669 - val_loss: 49.4999 - val_mae: 5.8531\n",
      "Epoch 72/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 29.8897 - mae: 4.2096 - val_loss: 38.3437 - val_mae: 4.9350\n",
      "Epoch 73/100\n",
      "12418/12418 [==============================] - 1s 68us/step - loss: 28.9625 - mae: 4.1368 - val_loss: 29.7420 - val_mae: 4.2241\n",
      "Epoch 74/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 28.0686 - mae: 4.0758 - val_loss: 27.2735 - val_mae: 4.0522\n",
      "Epoch 75/100\n",
      "12418/12418 [==============================] - 1s 71us/step - loss: 28.3878 - mae: 4.0991 - val_loss: 24.5669 - val_mae: 3.8062\n",
      "Epoch 76/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 28.5455 - mae: 4.0927 - val_loss: 27.0493 - val_mae: 4.0118\n",
      "Epoch 77/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 27.6873 - mae: 4.0480 - val_loss: 27.1006 - val_mae: 4.0113\n",
      "Epoch 78/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 27.7839 - mae: 4.0400 - val_loss: 27.1488 - val_mae: 4.0259\n",
      "Epoch 79/100\n",
      "12418/12418 [==============================] - 1s 68us/step - loss: 27.4416 - mae: 4.0244 - val_loss: 26.6920 - val_mae: 3.9806\n",
      "Epoch 80/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 27.0694 - mae: 3.9998 - val_loss: 34.7682 - val_mae: 4.6602\n",
      "Epoch 81/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 27.5251 - mae: 4.0328 - val_loss: 77.1939 - val_mae: 7.3753\n",
      "Epoch 82/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 29.7147 - mae: 4.1833 - val_loss: 25.1262 - val_mae: 3.8824\n",
      "Epoch 83/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 26.8439 - mae: 3.9772 - val_loss: 25.8577 - val_mae: 3.8364\n",
      "Epoch 84/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 27.4972 - mae: 4.0414 - val_loss: 27.7843 - val_mae: 4.1254\n",
      "Epoch 85/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 26.2657 - mae: 3.9353 - val_loss: 36.2343 - val_mae: 4.7075\n",
      "Epoch 86/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 26.6850 - mae: 3.9618 - val_loss: 24.3659 - val_mae: 3.7825\n",
      "Epoch 87/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 27.3322 - mae: 4.0098 - val_loss: 31.9774 - val_mae: 4.4878\n",
      "Epoch 88/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 27.6780 - mae: 4.0411 - val_loss: 29.1230 - val_mae: 4.2398\n",
      "Epoch 89/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 25.7793 - mae: 3.8983 - val_loss: 29.5967 - val_mae: 4.2854\n",
      "Epoch 90/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 24.9027 - mae: 3.8303 - val_loss: 46.8398 - val_mae: 5.5382\n",
      "Epoch 91/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 27.0051 - mae: 3.9884 - val_loss: 35.5477 - val_mae: 4.7073\n",
      "Epoch 92/100\n",
      "12418/12418 [==============================] - 1s 66us/step - loss: 25.6118 - mae: 3.8878 - val_loss: 52.5573 - val_mae: 5.9727\n",
      "Epoch 93/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 26.4428 - mae: 3.9365 - val_loss: 24.5295 - val_mae: 3.8371\n",
      "Epoch 94/100\n",
      "12418/12418 [==============================] - 1s 68us/step - loss: 26.3172 - mae: 3.9403 - val_loss: 41.9599 - val_mae: 5.2333\n",
      "Epoch 95/100\n",
      "12418/12418 [==============================] - 1s 65us/step - loss: 25.8213 - mae: 3.8964 - val_loss: 23.4019 - val_mae: 3.7331\n",
      "Epoch 96/100\n",
      "12418/12418 [==============================] - 1s 69us/step - loss: 25.6656 - mae: 3.8939 - val_loss: 27.0236 - val_mae: 4.0338\n",
      "Epoch 97/100\n",
      "12418/12418 [==============================] - 1s 68us/step - loss: 26.3975 - mae: 3.9527 - val_loss: 27.5589 - val_mae: 4.0402\n",
      "Epoch 98/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 24.9899 - mae: 3.8372 - val_loss: 48.7269 - val_mae: 5.7745\n",
      "Epoch 99/100\n",
      "12418/12418 [==============================] - 1s 67us/step - loss: 26.4526 - mae: 3.9341 - val_loss: 24.9211 - val_mae: 3.7994\n",
      "Epoch 100/100\n",
      "12418/12418 [==============================] - 1s 70us/step - loss: 25.0869 - mae: 3.8554 - val_loss: 31.2516 - val_mae: 4.4655\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=100,batch_size=32,validation_split=0.3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat= (7604, 1)\n",
      "average yield= 36.269806\n"
     ]
    }
   ],
   "source": [
    "yhat1=model.predict(x_test)\n",
    "avg_yield=np.mean(yhat1)\n",
    "print(\"yhat=\",yhat1.shape)\n",
    "print(\"average yield=\",avg_yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mse= 32.374886485136784\n",
      "Test rmse= 5.689893363248276\n",
      "Test mae= 4.5062538194756705\n"
     ]
    }
   ],
   "source": [
    "mse=np.mean(np.square(y_test-yhat1))\n",
    "rmse=np.sqrt(np.mean(np.square(y_test-yhat1)))\n",
    "mae=np.mean(abs(y_test-yhat1))\n",
    "print(\"Test mse=\",mse)\n",
    "print(\"Test rmse=\",rmse)\n",
    "print(\"Test mae=\",mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat= (17741, 1)\n"
     ]
    }
   ],
   "source": [
    "yhat2=model.predict(x_train)\n",
    "print(\"yhat=\",yhat2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse= 30.274459490025272\n",
      "train rmse= 5.502223140697337\n",
      "train mae= 4.37689132394775\n"
     ]
    }
   ],
   "source": [
    "mse=np.mean(np.square(y_train-yhat2))\n",
    "rmse=np.sqrt(np.mean(np.square(y_train-yhat2)))\n",
    "mae=np.mean(abs(y_train-yhat2))\n",
    "print(\"train mse=\",mse)\n",
    "print(\"train rmse=\",rmse)\n",
    "print(\"train mae=\",mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17741/17741 [==============================] - 0s 19us/step\n",
      "train score: [30.274459394847693, 4.376893043518066]\n",
      "7604/7604 [==============================] - 0s 20us/step\n",
      "test score: [32.37488616509917, 4.506254196166992]\n"
     ]
    }
   ],
   "source": [
    "s=model.evaluate(x_train,y_train)\n",
    "print(\"train score:\",s)\n",
    "\n",
    "st=model.evaluate(x_test,y_test)\n",
    "print(\"test score:\",st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 test score: 0.7354187954781959\n",
      "r^2 train score: 0.7507549768816193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"r^2 test score:\",r2_score(y_test,yhat1))\n",
    "print(\"r^2 train score:\",r2_score(y_train,yhat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
